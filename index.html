<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>tongyu's website</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
  <style>
    :root {
      --primary-color: #0a192f;
      --accent-color: #007bff;
      --bg-color: #ffffff;
      --text-color: #333;
      --text-light: #666;
      --border-color: #e0e0e0;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: var(--bg-color);
      color: var(--text-color);
      line-height: 1.6;
    }

    .layout {
      max-width: 960px;
      margin: 0 auto;
      padding: 40px 20px;
    }

    .profile-header {
      display: flex;
      align-items: center;
      gap: 20px;
      margin-bottom: 40px;
    }

    .profile-header img {
      width: 140px;
      height: 140px;
      border-radius: 50%;
      object-fit: cover;
    }

    .profile-info h2 {
      margin: 0;
      font-size: 24px;
    }

    .profile-info p {
      margin: 4px 0 0;
      color: var(--text-light);
      font-size: 14px;
    }

    .social-icons {
      margin-top: 10px;
    }

    .social-icons a {
      margin-right: 10px;
      font-size: 18px;
      color: var(--text-color);
      text-decoration: none;
      transition: color 0.2s ease;
    }

    .social-icons a:hover {
      color: var(--primary-color);
    }

    h1 {
      font-size: 28px;
      margin-top: 0;
      font-weight: 700;
    }

    h2 {
      font-size: 20px;
      margin-top: 40px;
      color: var(--primary-color);
    }

    ul {
      list-style-type: none;
      padding-left: 0;
    }

    li {
      margin-bottom: 15px;
    }

    a {
      color: var(--accent-color);
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .year, .contrib-heading {
      font-weight: bold;
      font-size: 16px;
      margin-top: 30px;
    }

    .sub-list {
      margin-top: 5px;
      margin-bottom: 15px;
    }

    @media (max-width: 768px) {
      .layout {
        padding: 20px;
      }

      .profile-header {
        flex-direction: column;
        align-items: flex-start;
      }
    }
  </style>
</head>
<body>
  <div class="layout">
    <div class="profile-header">
      <img src="https://github.com/tongyu0924.png" alt="Profile Picture">
      <div class="profile-info">
        <h2>徐家萱</h2>
        <p>National Taiwan University of Science and Technology, Department of Computer Science and Information Engineering
           Hsinchu Industrial Vocational High School, Department of Information Technology
           Passionate about competitive programming in high school, now focusing on AI-related research</p>
        <div class="social-icons">
          <a href="https://github.com/tongyu0924" target="_blank" aria-label="GitHub">
            <i class="fab fa-github"></i>
          </a>
          <a href="mailto:winnie920924@gmail.com" aria-label="Email">
            <i class="fas fa-envelope"></i>
          </a>
        </div>
      </div>
    </div>
    <!-- Main Content -->
    <div class="content">
      <h1>About Me</h1>
        <p>
          Hi, I'm Chia-Hsuan Hsu (<a href="https://github.com/tongyu0924" target="_blank">@tongyu0924</a>), 
          an undergraduate student majoring in Computer Science and Information Engineering at 
          National Taiwan University of Science and Technology (NTUST). In 2023 and 2024, I served as a 
          Core Team Member at Google Developer Groups (GDG) On Campus NTUST.
        </p>
        
        <p>
          My research focuses on computer vision (CV), large language models (LLMs), and multimodal learning. 
          I'm passionate about knowledge sharing and actively engaged in the developer community. 
          I also contribute to open-source projects in AI and machine learning, including 
          <a href="https://github.com/microsoft/autogen" target="_blank">microsoft/autogen</a>,
          <a href="https://github.com/huggingface/diffusers" target="_blank">huggingface/diffusers</a>, and
          <a href="https://github.com/scikit-learn/scikit-learn" target="_blank">scikit-learn</a>.
        </p>
        
        <p>
          I’m currently conducting research at Far Eastern Memorial Hospital, focusing on Large Language Models (LLMs) 
          and their integration with reinforcement learning (RL) and agent-based reasoning over electronic health records (EHRs).
        </p>
        
        <p>
          Previously, I worked on diffusion-based generative models at Academia Sinica, 
          and researched camera-based visual localization systems (e.g., VO/SLAM) at the 
          Human-Computer Interaction Lab, NTUST.
        </p>      
        
        <p>
          I also work part-time as an AI Engineer at <a href="https://toppansecurity.com/" target="_blank">Toppan Security</a>, a Japanese company that specializes in digital identity verification solutions.
        </p>
        
        <p>
          In addition, I'm a co-developer of the open-source project 
          <a href="https://github.com/JasonHonKL/spy-search" target="_blank">spy-search</a>, 
          which has received over 300 GitHub stars and 40 forks.
        </p>
        
        <p>
          Feel free to contact me. I'm always open to collaboration and meaningful exchange!
        </p>

      <h2>Currently Collaborating</h2>
      <ul>
        <li>
          <a href="https://github.com/JasonHonKL/spy-search" target="_blank">Spy-Search: A Modular Multimodal Agent for Fast Research QA</a> – 
          Co-developing a research project focused on an AI research assistant platform (★300+) that supports natural language queries, multimodal document QA, and tool-augmented reasoning by integrating both text and non-text modalities using LangChain and LLMs.

        </li>
      </ul>

      <h2>Publications</h2>
        <ul>
          <li>
            VSTFusion-VO: Monocular Visual Odometry with Video Swin Transformer Multimodal Fusion. <br />
            <em>IEEE International Conference on Advanced Robotics and Intelligent Systems (ARIS), 2025.</em> 
            [<a href="VSTFusion-VO.pdf" target="_blank">Paper</a>] [<a href="https://github.com/tongyu0924/VSTFusion-VO" target="_blank">Code</a>]
          </li>
        </ul>

      <h2>Projects</h2>
        <h3>AI / Machine Learning</h3>
        <ul>
          <li><a href="https://github.com/JasonHonKL/spy-search">Spy-Search</a> – Modular multimodal assistant for retrieval and QA, using LangChain and LLMs.</li>
          <li><a href="https://github.com/tongyu0924/VSTFusion-VO">VSTFusion-VO</a> – Visual odometry using Video Swin Transformer and depth fusion. Accepted at IEEE ARIS 2025.</li>
          <li><a href="https://github.com/tongyu0924/GPT-MultiRole-Debate-with-Speech">GPT Multi-Role Debate with Speech</a> – Multi-agent autonomous debate simulator with speech output.</li>
          <li><a href="https://github.com/tongyu0924/ORB-based-Visual-Odometry">ORB-based Visual Odometry</a> – VO system using ORB features and RANSAC for pose estimation.</li>
          <li><a href="https://github.com/tongyu0924/Secure-Diffusion-Watermarking-Survey">Secure Diffusion Watermarking Survey</a> – A study of traceability techniques in diffusion models.</li>
        </ul>

        <h3>Software Engineering</h3>
        <ul>
          <li><a href="https://github.com/tongyu0924/ntust-order-system">NTUST Order System</a> – Real-time food ordering platform built with Go and Firebase.</li>
          <li><a href="https://github.com/tongyu0924/ChessBoard">ChessBoard</a> – Interactive chess game in C++ using ImGui with sound and real-time stats.</li>
        </ul>


      <h2>Open Source Contributions</h2>
      <div class="contrib-heading">Major contributions:</div>
      <ul>
        <li>
          <strong><a href="https://github.com/microsoft/autogen">Microsoft AutoGen</a></strong>
          <ul class="sub-list">
            <li><a href="https://github.com/microsoft/autogen/pull/6057">PR #6057</a></li>
          </ul>
        </li>
        <li>
          <strong><a href="https://github.com/huggingface/diffusers">Hugging Face Diffusers</a></strong>
          <ul class="sub-list">
            <li><a href="https://github.com/huggingface/diffusers/pull/11426">PR #11426</a></li>
            <li><a href="https://github.com/huggingface/diffusers/pull/11427">PR #11427</a></li>
            <li><a href="https://github.com/huggingface/diffusers/pull/11431">PR #11431</a></li>
            <li><a href="https://github.com/huggingface/diffusers/pull/11475">PR #11475</a></li>
          </ul>
        </li>
      </ul>

      <div class="contrib-heading">Other notable contributions:</div>
      <ul>
        <li><a href="https://github.com/the-turing-way/the-turing-way">The Turing Way</a> – Outside collaborator</li>
        <li><a href="https://github.com/scikit-learn/scikit-learn">Scikit-learn</a></li>
        <li><a href="https://github.com/argilla-io/distilabel">Argilla-io Distilabel</a></li>
        <li><a href="https://github.com/tensorzero/tensorzero">TensorZero</a></li>
        <li><a href="https://github.com/ersilia-os/ersilia">Ersilia</a></li>
        <li><a href="https://github.com/harmonydata/harmony">Harmony</a></li>
      </ul>

      <h2>一些高中的東西</h2>
      <ul>
        <li><a href="interview_2022.html">111台科資工面試</a> – 台科資工面試題目 & 心得</li>
        <li><a href="https://hackmd.io/@TKVTzbKbQva3_DI0FGIcGw/B1OVx19VK">圖論</a> – 歐拉路徑&漢米爾頓路徑</li>
        <li><a href="https://hackmd.io/@TKVTzbKbQva3_DI0FGIcGw/rkek9NUWgg">AP325圖論</a> – AP325圖論程式碼</li>
      </ul>
    </div>
  </div>

</body>
</html>

